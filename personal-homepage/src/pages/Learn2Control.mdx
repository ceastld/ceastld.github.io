import React from 'react';
import BackButton from '../components/BackButton';

<BackButton />

# Learn2Control: 可学习高斯嵌入的扩散头像控制

## 论文概述

**论文标题**: Controlling Avatar Diffusion with Learnable Gaussian Embedding

**发表会议**: SIGGRAPH Asia 2025

**论文链接**: [Controlling Avatar Diffusion with Learnable Gaussian Embedding](https://arxiv.org/abs/2503.15809)

**项目主页**: [https://ustc3dv.github.io/Learn2Control/](https://ustc3dv.github.io/Learn2Control/)

## 研究问题

数字人物（头部）的生成和动画化在AR/VR、影视等领域有重要应用。论文指出现有方法的主要问题：

### 1. 控制信号表达能力差
传统方法用地标点（landmarks）、法向图（normal maps）或深度图（depth maps）控制生成，但这些信号存在缺陷：
- **地标点太稀疏**：难以捕捉细微的面部肌肉运动
- **法向图和深度图是相机相关的**：依赖于视角，不具有3D一致性

### 2. 3D一致性和运动准确性差
当控制信号本身不一致时，扩散模型生成的结果也会出现不一致

### 3. 数据多样性不足
公开数据集中的身份和姿态变化有限，导致模型泛化能力弱

## 核心创新

### 1. 可学习高斯嵌入控制信号

论文的主要创新是用**可学习的高斯场**作为控制信号，而不是传统的视觉线索。

**工作原理：**
- 在FLAME参数化头部模型的UV空间中维护一个高斯场
- 每个高斯由以下属性定义：位置($x_0$)、尺度($s$)、不透明度($o$)和**可学习特征**($f$)
- 简化的高斯公式：$g(x) = e^{-\frac{1}{2s}\|x-x_0\|_2^2}$

**优势对比：**

| 特性 | 地标点 | 法向图/深度图 | 可学习高斯 |
|------|-------|-------------|----------|
| 密度 | 稀疏 | 密集 | 密集 ✓ |
| 自适应 | 固定 | 固定 | 可学习 ✓ |
| 表达力 | 有限 | 有限 | 丰富 ✓ |
| 3D一致性 | 是 | 否 | 是 ✓ |

### 2. 表面嵌入流程

1. 追踪目标视频得到FLAME参数：形状($\beta$)、姿态($\theta, \psi$)、表情系数
2. 将UV空间的高斯根据FLAME表面变形变换到3D空间
3. 根据相机参数，投影并"splatting"（泼溅）这些3D高斯到2D特征图
4. 生成的特征图$F$作为扩散模型的控制信号

### 3. 合成数据集方案

生成了包含**10,000个不同身份**的大规模合成数据集：
- 使用SphereHead生成3D一致的多视角头部图像
- 每个身份约60张图像（yaw角[-60°, 60°]，pitch角[-30°, 45°]）
- 引入**可学习的real/synthetic标记**处理合成数据的artifacts问题

## 技术方法

### 参考引导的扩散框架

采用**双分支架构**：

**参考分支：** 提取参考图像特征，通过共享注意力机制注入细节

**去噪分支：** 
- 接收噪声隐空间$z_t$和控制特征$F$
- 使用共享注意力整合参考特征
- 使用时间层保证时间一致性

**损失函数：** 使用v-parameterization的简单MSE损失
$$L(\theta, \phi) = E_{z_0,t,\epsilon}(\|v_\theta(z_t, C, z_{ref}) - v\|_2^2)$$

## 实验结果

### 定量结果

在VFHQ和NeRSemble两个测试集上显著优于现有方法：

**改进指标：**
- **LPIPS**（感知相似度）：0.099 vs 0.103（X-Portrait）
- **CSIM**（身份保存）：0.831 vs 0.813（X-Portrait）
- **AED**（表情准确度）：0.123 vs 0.137（X-Portrait）
- **APD**（姿态准确度）：0.014 vs 0.019（X-Portrait）

### 定性结果

- **身份保留**：即使在参考图和驱动帧姿态差异大时，仍能准确保留身份
- **表情精确度**：能生成更夸张的表情
- **3D一致性**：novel view synthesis实验表明，在大姿态变化下（±50°）仍能保持一致性

---

<BackButton />